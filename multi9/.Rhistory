ggtitle("Boxplot de Razonamiento Matematico") +
xlab("CONDICION")+
ylab( "Nota " )
p2
hist(datos1$RM,col="steelblue",main = "RAZONAMIENTO MATEMATICO",
xlab = "Notas en RM",ylab = "Frecuencia")
plot(density(datos1$RM))
polygon(density(datos1$RM),col='#f8f025',border = 'white')
lines(density(datos1$RM),col='#000000')
multi.hist(x = datos1[,1:9], dcol = c("blue", "red"), dlty = c("dotted", "solid"),
main = "")
data <- datos1[,-10]
head(data)
data <- data %>%
gather(key="text", value="value") %>%
mutate(text = gsub("\\.", " ",text)) %>%
mutate(value = round(as.numeric(value),0))
p <- data %>%
mutate(text = fct_reorder(text, value)) %>%
ggplot( aes(x=value, color=text, fill=text)) +
geom_histogram(alpha=0.6, binwidth = 5) +
scale_fill_viridis(discrete=TRUE) +
scale_color_viridis(discrete=TRUE) +
theme_ipsum() +
theme(
legend.position="none",
panel.spacing = unit(0.1, "lines"),
strip.text.x = element_text(size = 8)
) +
xlab("") +
ylab("Assigned Probability (%)") +
facet_wrap(~text)
p
EDA(datos$RV)
plot_normality(datos,RV,col = "green2")
plot_normality(datos,MAT,col = "violet")
plot_normality(datos,QUI,col = "purple")
p <- datos1 %>%
ggplot( aes(x=datos1$RM, fill=datos1$CON)) +
geom_histogram( color="#e9ecef", alpha=0.7, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080")) +
theme_ipsum() +
labs(fill="CONDICION")+
xlab("Notas en Razonamiento Matematico")+
ylab( "Frecuencia de Postulantes" )
p
plot1 <- ggplot(data = datos1, aes(x = RV)) +
geom_density(aes(colour = CON)) + theme_bw()
plot1
datosacp <- datos[,c(-1,-11)]
summary(datosacp)
summarytools::descr(datosacp)
X=datosacp$RM
Xbar=mean(datosacp$RM)
Sd=sd(X)
mean(((X-Xbar)/Sd)^3)# Asimetria Muestral
mean(((X-Xbar)/Sd)^4)-3# Curtosis muestral
summarytools::descr(datosacp)
with(datos1, stby(RM, CON, descr))
round(stat.desc(datosacp),2)
round(stat.desc(datosacp,basic=FALSE),2)
setwd("C:/Users/usuario5810/Downloads")
# Pregunta 2
# Entrada de datos
Datos<-read.table("MLII_PD_Clase_06_Datos01.csv",header=TRUE,sep=";")
# Pregunta 2
# Entrada de datos
Datos<-read.table("MLII_PD_Clase_06_Datos01.csv",header=TRUE,sep=";")
attach(Datos)
#detach(Datos)
str(Datos)
# Estimación de los coeficientes de regresión
Modelo1<-glm(Y_Produccion~., data=Datos, family=binomial(link=logit))
summary(Modelo1)
Datos
#detach(Datos)
str(Datos)
Datos$X2_Fertiliza <- as.factor(Datos$X2_Fertiliza)
Datos$X3_Tecnologia <- as.factor(Datos$X3_Tecnologia)
Datos$Y_Produccion <- as.factor(Datos$Y_Produccion)
# Estimación de los coeficientes de regresión
Modelo1 <- glm(Y_Produccion~., data=Datos, family=binomial(link=logit))
summary(Modelo1)
# Prueba de significación del modelo de regresión
Alfa=0.05
Chi_Tab=qchisq(1-Alfa,Modelo1$df.residual); Chi_Tab
p_valor=1-pchisq(Modelo1$deviance,Modelo1$df.residual); p_valor
# Coeficiente de determinación
R2= (1-Modelo1$deviance/Modelo1$null.deviance)*100; R2
# Cálculo de los Odds Ratios
exp(coef(Modelo1))
# Prueba de significación del modelo de regresión
Alfa=0.05
Chi_Tab=qchisq(1-Alfa,Modelo1$df.residual); Chi_Tab
p_valor=1-pchisq(Modelo1$deviance,Modelo1$df.residual); p_valor
qchisq(0.95, 933)
qchisq(0.95, 938)
qchisq(0.95, 833)
# Cálculo de los Odds Ratios
exp(coef(Modelo1))
# IC para los coeficientes y OR
NC=0.95
confint.default(Modelo1, level=NC)
exp(confint.default(Modelo1, level=NC))
# Predicción para nuevos productores
Xo=c(1,8,1,1,0,768,577); P_Xo=sum(Xo*coef(Modelo1)); P=1/(1+exp(-(P_Xo))); P
Xo=c(1,6,0,1,0,809,579); P_Xo=sum(Xo*coef(Modelo1)); P=1/(1+exp(-(P_Xo))); P
Xo=c(1,3,0,0,1,1008,569); P_Xo=sum(Xo*coef(Modelo1)); P=1/(1+exp(-(P_Xo))); P
Xo=c(1,3,1,0,0,1358,512); P_Xo=sum(Xo*coef(Modelo1)); P=1/(1+exp(-(P_Xo))); P
Xo=c(1,4,1,0,0,961,599); P_Xo=sum(Xo*coef(Modelo1)); P=1/(1+exp(-(P_Xo))); P
# Regresión logística para la clasificación
f=table(Datos$Y_Produccion); fr=round(prop.table(f)*100,1)
Tabla=as.data.frame(cbind(f,fr)); Tabla
# Dividir la base de datos: Entrenamiento (70%) y Prueba (30%)
set.seed(100)
indice <- sample(2, nrow(Datos), replace = TRUE, prob = c(0.7, 0.3))
Datos_E <- Datos[indice == 1,] #Datos para el entrenamiento (70%)
Datos_P <- Datos[indice == 2,] #Datos para la prueba (30%)
f=table(Datos_E$Y_Produccion); fr=round(prop.table(f)*100,1)
Tabla_E=as.data.frame(cbind(f,fr)); Tabla_E
f=table(Datos_P$Y_Produccion); fr=round(prop.table(f)*100,1)
Tabla_P=as.data.frame(cbind(f,fr)); Tabla_P
# Regresión logística binaria con datos de entrenamiento
Modelo1_1<-glm(Y_Produccion~X1_Tamano_Predio+X2_Fertiliza+X3_Tecnologia+X4_Ing_Agricola+X5_Ing_Pecuario, data=Datos_E, family=binomial(link=logit))
summary(Modelo1_1)
exp(coef(Modelo1_1))
# Elaboración de la Tabla de confusión (R considera: Si Pi<=0.5, Y=1)
Prediccion <-predict(Modelo1_1, Datos_P, type="response")
Pred=rep("No_Aumento", length(Prediccion))
Pred[Prediccion>=0.5]= "Si_Aumento"
Tabla_Conf=table(Datos_P$Y_Produccion, Pred,dnn=c("Observado:"," Predecido:"))
Tabla_Conf
141/145
109/114
141/146
109/113
VP
# Dividir la base de datos: Entrenamiento (70%) y Prueba (30%)
set.seed(100)
indice <- sample(2, nrow(Datos), replace = TRUE, prob = c(0.7, 0.3))
Datos_E <- Datos[indice == 1,] #Datos para el entrenamiento (70%)
Datos_P <- Datos[indice == 2,] #Datos para la prueba (30%)
f=table(Datos_E$Y_Produccion); fr=round(prop.table(f)*100,1)
Tabla_E=as.data.frame(cbind(f,fr)); Tabla_E
f=table(Datos_P$Y_Produccion); fr=round(prop.table(f)*100,1)
Tabla_P=as.data.frame(cbind(f,fr)); Tabla_P
# Regresión logística binaria con datos de entrenamiento
Modelo1_1<-glm(Y_Produccion~X1_Tamano_Predio+X2_Fertiliza+X3_Tecnologia+X4_Ing_Agricola+X5_Ing_Pecuario,
data=Datos_E, family=binomial(link=logit))
summary(Modelo1_1)
exp(coef(Modelo1_1))
# Elaboración de la Tabla de confusión (R considera: Si Pi<=0.5, Y=1)
Prediccion <-predict(Modelo1_1, Datos_P, type="response")
Pred=rep("No_Aumento", length(Prediccion))
Pred[Prediccion>=0.5]= "Si_Aumento"
Tabla_Conf=table(Datos_P$Y_Produccion, Pred,dnn=c("Observado:"," Predecido:"))
Tabla_Conf
# Métricas para medir la precisión de un clasificador
VP=Tabla_Conf[1,1]; FN=Tabla_Conf[1,2]; FP=Tabla_Conf[2,1]; VN=Tabla_Conf[2,2]; N=VP+FN+FP+VN
TA=((VP+VN)/N)*100; round(TA,1)
TE=((FN+FP)/N)*100; round(TE,1)
TVP=(VP/(VP+FN))*100; round(TVP,1)
TVN=(VN/(FP+VN))*100; round(TVN,1)
TFP=(FN/(VP+FN))*100; round(TFP,1)
TFN=(FP/(VN+FP))*100; round(TFN,1)
PP=(VP/(VP+FP))*100; round(PP,1)
PN=(VN/(VN+FN))*100; round(PN,1)
VP
VN
length(Datos_P)
dim(Datos_P)
N
Datos_P
# Elaboración de la Tabla de confusión (R considera: Si Pi<=0.5, Y=1)
Prediccion <-predict(Modelo1_1, Datos_P, type="response")
Pred=rep("No_Aumento", length(Prediccion))
Pred[Prediccion>=0.5]= "Si_Aumento"
Tabla_Conf=table(Datos_P$Y_Produccion, Pred,dnn=c("Observado:"," Predecido:"))
Tabla_Conf
# Métricas para medir la precisión de un clasificador
VP=Tabla_Conf[2,2]; FN=Tabla_Conf[2,1]; FP=Tabla_Conf[1,2]; VN=Tabla_Conf[1,1]; N=VP+FN+FP+VN
TA=((VP+VN)/N)*100; round(TA,1)
TE=((FN+FP)/N)*100; round(TE,1)
TVP=(VP/(VP+FN))*100; round(TVP,1)
TVN=(VN/(FP+VN))*100; round(TVN,1)
TFP=(FN/(VP+FN))*100; round(TFP,1)
TFN=(FP/(VN+FP))*100; round(TFN,1)
PP=(VP/(VP+FP))*100; round(PP,1)
PN=(VN/(VN+FN))*100; round(PN,1)
Tabla_Conf
# Métricas para medir la precisión de un clasificador
VP=Tabla_Conf[2,2]; FN=Tabla_Conf[2,1]; FP=Tabla_Conf[1,2]; VN=Tabla_Conf[1,1]; N=VP+FN+FP+VN
VP
TA=((VP+VN)/N)*100; round(TA,1)
TE=((FN+FP)/N)*100; round(TE,1)
TVP=(VP/(VP+FN))*100; round(TVP,1)
TVN=(VN/(FP+VN))*100; round(TVN,1)
TFP=(FN/(VP+FN))*100; round(TFP,1)
TFN=(FP/(VN+FP))*100; round(TFN,1)
PP=(VP/(VP+FP))*100; round(PP,1)
PN=(VN/(VN+FN))*100; round(PN,1)
Tabla_Conf
Tabla_Conf
# Predicción de nuevos datos
Datos_N<-read.table("MLII_PD_Clase_06_Datos01_Nuevos.csv",header=TRUE,sep=";")
detach(Datos)
attach(Datos_N)
Prediccion_N <-predict(Modelo1_1, Datos_N, type="response")
Pred_N=rep("No_Aumento", length(Prediccion_N))
Pred_N[Prediccion_N>=0.5]= "Si_Aumento"
Tabla_N=as.data.frame(cbind(Prediccion_N,Pred_N)); Tabla_N
rm(list = ls())
alpha <- 70
beta <- 100
a <- 6
b <- 14
# Función de transformación de Beta(α, β) a intervalo [a, b]
transform_beta <- function(x, a, b) {
a + (b - a) * x
}
# Desviación estándar poblacional real (de X_real)
var_beta <- function(alpha, beta) {
(alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))
}
sd_beta <- sqrt(var_beta(alpha, beta)) * (b - a)
# Simulación
set.seed(123)
n_sim <- 1000
sample_sizes <- seq(10, 1000, by = 10)
sd_estimates <- sapply(sample_sizes, function(n) {
x <- rbeta(n, alpha, beta)
x_real <- transform_beta(x, a, b)
sd(x_real)
})
# Gráfico
plot(sample_sizes, sd_estimates, type = "l", col = "blue",
xlab = "Tamaño de muestra", ylab = "Desviación estándar muestral",
main = "Convergencia de SD muestral a SD poblacional")
abline(h = sd_beta, col = "red", lty = 2)
legend("topright", legend = c("Estimación muestral", "SD poblacional"),
col = c("blue", "red"), lty = c(1, 2))
# Parámetros de la distribución Gamma
r <- 2   # forma
lambda <- 1  # escala
# Parámetros de la transformación
alpha <- 6
b <- 14
# Número de simulaciones
n_simulations <- 10000
n_sample <- 100  # tamaño de la muestra
# Generación de las muestras aleatorias de X (energía)
set.seed(123)  # Para reproducibilidad
X <- matrix(rgamma(n_simulations * n_sample, shape = r, scale = lambda),
ncol = n_sample, nrow = n_simulations)
# Aplicando la transformación T = alpha * X + b
T <- alpha * X + b
# Calcular la media de cada muestra T
T_bar <- rowMeans(T)
# Mostrar la distribución de T
hist(T_bar, breaks = 30, main = "Distribución de T", xlab = "T", col = "lightblue", border = "black")
# Mostrar la distribución de la media
mean(T_bar)
sd(T_bar)
# Graficar la distribución exacta y la distribución límite de T (media muestral)
# Asumimos que la media de T se aproxima a la distribución normal debido al teorema central del límite
# Agregar una curva normal para la distribución límite de T
curve(dnorm(x, mean = mean(T_bar), sd = sd(T_bar)), col = "red", add = TRUE)
# Mostrar valores teóricos
mean_theoretical <- alpha * r * lambda + b
sd_theoretical <- sqrt(r * lambda^2) * alpha
cat("Media teórica de T: ", mean_theoretical, "\n")
cat("Desviación estándar teórica de T: ", sd_theoretical, "\n")
set.seed(100
)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
rm(list = ls())
# Parámetros de la distribución Beta
alpha <- 70
beta <- 100
a <- 6
b <- 14
# Función de transformación de Beta(α, β) a intervalo [a, b]
transform_beta <- function(x, a, b) {
a + (b - a) * x
}
# Desviación estándar poblacional real (de X_real)
var_beta <- function(alpha, beta) {
(alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))
}
sd_beta <- sqrt(var_beta(alpha, beta)) * (b - a)
# Simulación
n_sim <- 1000
sample_sizes <- seq(10, 1000, by = 10)
sd_estimates <- sapply(sample_sizes, function(n) {
x <- rbeta(n, alpha, beta)
x_real <- transform_beta(x, a, b)
sd(x_real)
})
# Gráfico
plot(sample_sizes, sd_estimates, type = "l", col = "blue",
xlab = "Tamaño de muestra", ylab = "Desviación estándar muestral",
main = "Convergencia de SD muestral a SD poblacional")
abline(h = sd_beta, col = "red", lty = 2)
legend("topright", legend = c("Estimación muestral", "SD poblacional"),
col = c("blue", "red"), lty = c(1, 2))
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100
)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
set.seed(100)
# Parámetros
alpha <- 0.05
mu <- 3
delta <- 2
n <- 90
# Simulación de muestra de tamaño 90 de una exponencial desplazada
X <- rexp(n, rate = 1/mu) + delta
# Método empírico (mínimo)
delta_hat_emp <- min(X)
limite_superior_emp <- delta_hat_emp + mu * log(1 / alpha)
cat("Intervalo por método empírico:\n")
cat("[", round(delta_hat_emp, 3), ",", round(limite_superior_emp, 3), "]\n")
# Método usando el máximo
delta_hat_max <- max(X) - mu * log(n)
limite_inferior_max <- delta_hat_max
limite_superior_max <- max(X)
cat("Intervalo usando el máximo:\n")
cat("[", round(limite_inferior_max, 3), ",", round(limite_superior_max, 3), "]\n")
